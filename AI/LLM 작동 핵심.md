

### 통계적 언어 모델 (Statistical Language Model)
- 통계적 언어 모델이란, 특정 문장 s에 대해 그 문장이 말해질 가능성 p(s)를 계산하는 모델을 의미한다.

```
"Hello, how are you?"
"I am _______, ______ _______. _______ _____?"

a) fine, thank you. And you?
b) okay, I guess. But why?
```

`a`와 `b` 둘 다 맥락상 들어갈 수 있는 문장이다. 하지만 우리는 대부분 `a`라고 생각을 할 것이다.

이는 우리가 일상 대화나 교과서에서 수없이 반복해서 접하며 가장 익숙해진 패턴이기 때문이다.

즉, 우리의 뇌가 과거의 수많은 언어 경험을 바탕으로 이 질문 뒤에는 `a`가 올 확률이 높다고 무의식적으로 계산한 결과이다.

### 문장이 말해질 가능성을 어떻게 계산할까?
문장이 $$s = a_1 a_2 a_3 a_4 ... a_n$$ 이라고 하면 $$p(s) = p(a_1) p(a_2 | a_1) p(a_3 | a_1 a_2) ... p(a_n | a_1 a_2 ... a_{n-1})$$이다.

문제점 : 계산량이 너무 많음

### Ngram 기반 언어 모델
N-Gram : 문장을 단어 n개씩 자른 단위

"통계적 언어 모델은 다음 단어가 무엇인지 통계적으로 예측하는 수학적 장치이다."
3-grams : (통계적, 언어, 모델은), (언어, 모델은, 다음), (모델은, 다음, 단어가), (다음, 단어가, 무엇인지) ... (예측하는, 수학적, 장치이다)

다음과 같은 방식으로 nGram 분석만으로도 전체 문장의 확률은 근사할 수 있다.

$$p(a_i | a_1 a_2 ... a_{i-1}) \approx p(a_i | a_{i-2} a_{i-1})$$

앞에 나온 몇 단어를 보면, 다음에 나올 단어의 확률을 구할 수 있다.

$$p(a_i | a_{i-2} a_{i-1}) = count(a_{i-2} a_{i-1} a_i) / count(a_{i-2} a_{i-1} *)$$


프로그래밍 언어도 자연어와 비슷하다.

코드의 상당 부분은 반복적이고 정형화되어 있다.

프로그래밍 언어의 문법을 고려하는 대신, n-gram에 기반한 통계적 분석만으로 높은 정확도를 가지는 자동완성 엔진을 만드는 것 또한 증명되어왔다.

``` python
python 프로그램

for ___________

a) i in range(
b) (int i=0; i<
```


### 트랜스포머(Transformer) 기반 LLM
> 딥러닝 기반의 인공신경망 모델

트랜스포머의 핵심인 '셀프 어텐션(Self-Attention)' 메커니즘은 문장 내의 모든 단어가 서로 어떤 연관성을 가지는지 계산한다.

### 대규모 언어 모델 (Large Language Model)
> 내부 구조가 다르지만 근본적으로 매우 거대하고 강력한 통계적 언어모델

근본적으로 Transformer 아키텍처를 바탕으로 다음 토큰 예측 (Next Token Prediction)을 자기회귀(auto-regressive) 방식으로 학습한 통계적 언어 모델이다.

### 대규모 언어 모델의 창발적 능력 (Emergent Capability)
창발 : 구성 요소에는 없는 특징이 전체 구조에서 자발적으로 나타남
- 대규모 언어 모델을 구성하는 인공신경망의 규모를 키우고 많은 양의 데이터를 이용해 학습했더니, 학습 목표로 삼지 않았던 기능이 창발적으로 나타나는 것을 확인

대규모 언어 모델은 맥락으로 주어진 텍스트의 의미를 이해하고 이를 바탕으로 응답을 생성할 수 있다.

이를 바탕으로, 프롬프트(맥락에 해당하는 텍스트)를 어떻게 구성하냐에 따라 새로운 업무를 처리하도록 유도할 수 있다.

### 프롬프트 엔지니어링
대표적인 프롬프트 엔지니어링은 아래와 같다.

#### N-shot Learning
> - Zero-shot Learning : 아무런 예시 없이 단순히 지시만으로 특정 업무를 수행
> - One-shot Learning : 예시를 하나 주고 이의 변형인 업무를 수행
> - Few-shot Learning : 예시를 몇 개 주고 이의 변형인 업무를 수행

#### Chain-of-Thoughts
맥락을 통해 보다 논리적인 추론을 하도록 유도하면, LLM이 내놓는 최종적인 답의 정확도가 높아진다.

프롬프트 뒤에 "차근차근 생각해보자" (step by step) 라고 덧붙이는 것만으로도 LLM의 정확도가 높아진다.

(기존의 LLM은 복잡한 문제에 대해 중간 과정을 놓쳐 오류를 범하기 쉽기 때문에 `Chain-of-Thoughts`가 효과적이다.)
> DeepSeek-R1처럼 추론을 내재한 Reasoning Model도 존재한다.

#### Self-Consistency
> 자기일관성 : 같은 질문을 여러 번 하고, 다수결로 답을 정하면 더 정확하다.
> Voting (다수결 투표) : 여러 번 반복해서 다양한 추론 경로를 생성 -> 최종 답변들 중 가장 많이 등장한 답을 최종 정답으로 채택

### 대규모 언어 모델의 한계 극복과 확장

#### RAG
> 모델이 답변을 생성하기 전에, 외부 데이터베이스(문서, 사내 자료 등)에서 관련된 정보를 먼저 검색(Retrieval)해 온 뒤, 그 정보를 프롬프트에 포함시켜 답변을 생성(Generation)하는 기술

#### Reason + Act (ReAct)
> LLM이 스스로 생각(Reason)하고, 외부 도구를 사용하기 위한 행동(Act)을 번갈아 가며 수행하도록 유도하는 프롬프트 방식
